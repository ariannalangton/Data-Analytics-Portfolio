# Arianna Langton - Data Analyst Portfolio
## About
Hello, I'm Arianna! I hold a Bachelor's degree in Physics with a minor in Mathematics, providing me with a strong analytical foundation in both the physical sciences and mathematics. My passion for problem-solving and mathematics has naturally led me toward a career in data analytics. I have earned both the Google Data Analytics and Google Advanced Data Analytics Certificates and am currently working toward completing the Google Business Intelligence Certificate. This will not only build on my data analytics expertise but also deepen my understanding of the business analytics field. 

Throughout my studies, I refined my ability to analyze complex datasets and developed a keen eye for spotting patterns and trends. My experience with data management and statistical analysis has helped me develop a technical mindset that I believe will be a valuable asset in my role as a data specialist. I’m eager to apply my technical and analytical skills to the data science industry as an entry-level data specialist.

In my spare time, I enjoy exploring new data analysis tools and techniques, always seeking opportunities to further expand my knowledge and skillset. Whether collaborating on a team or working independently, I thrive on uncovering insights and solving complex problems through data. My current technical skills include SQL, Tableau, Python, and Excel, alongside deep understanding of mathematics..

This is a repository to showcase skills, share projects and track my progress in Data Analytics.
## Table of Contents
- [About](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#about)
- [Portfolio Projects](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#portfolio-projects)
  - [Python](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Python)
    -  [(Ad Campaign Comparison)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Analyzing-Ad-Platform-Success)
    -  [(Marketing Budget ROI Analysis)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#analyzing-marketing-campaigns-on-different-platforms)
      - [(Miscellanious Statistical Analysis Projects)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/pythonProjects/misc_statsiticalAnalysisProjects) 
        - [(EDA of TikTok Claim Classification)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#analyzing-tiktok-video-statistics)
        - [(Investment Analysis)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Analyzing-Industries-and-Countires-for-Investments)
        - [(Air Quality Analysis )](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Air-Quality-Probability-Density)
        - [(Literacy Data Analysis)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Literacy-Data-Probability-Density)      
        - [(NASA Meteorite Analysis)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Analyzing-Meteroite-Landings-Recorded-by-NASA)
        - [(Chaotic Systems of Differential Equations)](https://github.com/ariannalangton/Portfolio/blob/main/README.md#Chaotic-Systems-of-Differenital-Equations)
  - [SQL](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#SQL)
    - [(Business Insights)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Generating-and-Analyzing-Business-Data)
    - [(Business Optimization)]
  - [Excel](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Excel-and-Sheets)
    - [Marketing Campaign Plan]
    - [(Clean Data for a Gym Directory)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Cleaning-Web-Scraped-Data-for-a-Directory)
  - [Tableau](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Tableau)
    - [(My Tableau Public)](https://public.tableau.com/app/profile/arianna.langton5684/vizzes)
      - [(Ad Campaign Comparison)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Ad-Campaign-Comparison)
      - [(Minnesota Traffic Volume Analysis)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Minnesota-Traffic-Volume-Analysis)
      - [(U.S Women Elected Officals dashboard)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Women-Elected-Officials)
      - [(Grocery Store KPI Dashboard)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Grocery-Store-KPI-Dashboard)
      - [(League of Legends V13.1 Statistics)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#League-of-Legends-Statistics)
      - [(Google Fiber Repeat Calls)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#Google-Fiber-Repeat-Calls-Analysis)
      - [(EDA of TikTok Claim Classification)](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#EDA-of-TikTok-Claim-Classification)
- [Education](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#education)  
- [Certifications](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#certificates)
- [Contact](https://github.com/ariannalangton/Data-Analytics-Portfolio/blob/main/README.md#contacts)
 
## Portfolio Projects
In this section I will list data analytics projects briefly describing the technology stack used to solve cases.

## Highlighted Projects

### Comparing TikTok, Facebook, and Google for an Ad Success

**Overview:** [(Ad Platform Comparison)](https://github.com/ariannalangton/Portfolio/tree/main/ad_campaign_comparison)   

**Platform Folders:** <br> [(Facebook Ad Analysis)](https://github.com/ariannalangton/Portfolio/tree/main/ad_campaign_comparison/facebook) <br> [(TikTok Ad Analysis)](https://github.com/ariannalangton/Portfolio/tree/main/ad_campaign_comparison/tiktok) <br> [(Google Ad Analysis)](https://github.com/ariannalangton/Portfolio/tree/main/ad_campaign_comparison/google)

**Code:**
  - TikTok <br>
    - [(Tiktok Ads Statistical Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/ad_campaign_comparison/tiktok/tiktok_analysis.ipynb)
  - Facebook <br>
    - [(Facebook Ads Statistical Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/ad_campaign_comparison/facebook/Facebook_Ad_Statistical_Analysis.ipynb)
  - Google <br>
    - [(Google Ads Statistical Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/ad_campaign_comparison/google/google_analysis.ipynb) 

**Dashboards:** 
  - TikTok <br>
    - [(TikTok Demographics Dashboards)](https://public.tableau.com/app/profile/arianna.langton5684/viz/TikTokDemographicDataDashboards/Metrics)
    - [(TikTok Metrics Dashboard)](https://public.tableau.com/app/profile/arianna.langton5684/viz/TiktokAdMetricsDashboards/Story1)
  - Facebook <br>
    - [(Facebook Ad Campaign Dashboard)](https://public.tableau.com/app/profile/arianna.langton5684/viz/FacebookAdCampaignReachAnalysis/Story1#1)
  - Google <br>
    - [(Google Ad Campaign Dashboard)](https://public.tableau.com/app/profile/arianna.langton5684/viz/GoogleAdCampaignAnalysis/Story1#1)
  - Overall Comparison <br>
    - [(Comparison Dashboard)](https://public.tableau.com/app/profile/arianna.langton5684/viz/AdPlatformComparison/Dashboard1)  

**Goal:** Apply data cleaning and formatting techniques to prepare data for creating dashboards that showcase key metrics, including impressions, conversion rate, click-through rate, and demographic information across Facebook, TikTok, and Google Ads platform. Additionally, conduct statistical analysis to validate that observed trends are statistically significant and reliable for future decision-making. Finally, perform a comprehensive review to determine which platform delivered the best performance.

**Description:** For this project, I analyzed data provided by a digital media specialist who ran ads across Facebook, TikTok, and Google Ads platforms. My analysis focused on the statistical significance of demographic data, specifically age and gender. I also examined the times of day when the ads received the most views. Additionally, I calculated the expected conversion rate, click-through rate, and impressions to conversion rate using a 95% confidence interval, as well as evaluating the cost using either CPM (cost per thousand impressions) or CPC (cost per click) to identify the most effective demographics to target. Finally, I compared the overall success of the campaigns by analyzing metrics such as cost and conversion rate to determine which platform was the most successful.

**Skills:** data cleaning, data analysis, data visualization, statisical analysis, hypothesis testing.

**Technology:** Python, Pandas, Numpy, Matplotlib, scipy, tableau

**Results:** An overview of the results for each platform is below.
- Facebook
  - Males viewed the ad significantly more than females, in terms of reach and impressions, which was confirmed through statistical testing. There was some indication that the reach-to-impression ratio between genders may differ, the p-value of 0.08 suggests that further investigation is needed to draw firm conclusions.
  - The age group 55-64 stood out as the most frequent viewers, with a significant 99% difference from the lowest group, indicating a strong preference for this demographic.
  - The ad was most frequently seen during early morning hours, lunch breaks, and late afternoon, aligning with typical routines of the older demographic. However, due to the minor differences in impressions during the top viewing hours, more data is required to determine the most effective time for ad placements.
  - It performed well in terms of conversion and click-through rates, surpassing industry averages. The 30% conversion rate is particularly notable, but the relatively low impression-to-conversion rate (1.4%).
- Tiktok
  -  Using a two-sample z-test it was found women had significantly more impressions than men, however there was no significant difference in conversion rate (CVR) or click rate (CTR) by gender.
  -  Using a one way ANOVA test it was revealed that age had no effect on CVR or CTR. Using a post-hoc tukey test it was revealed that the age group with the most conversions was the 55+ group, with 18-25 having the least. .
  -  Two-way ANOVA test for age and gender revealed the females in the 18-25 group had the lowest conversions and men in the 55+ age group had the most. This indicates older people, men specifically, are more likely to convert, and younger people, women specifically, are less likely to convert.
  -  An ANOVA test was used to analyze what days of the week recieved the most impressions, showing that Sunday had the most, follwoed by Saturday, and that this is signigicantly different than the rest.
  -  A one way ANOVA test revealed that the times that recieved the most views were 8PM, 10PM, 9PM, 7PM, 6PM, all occurring during the evening when people are generally more available after work and school.
- Google
  - Women viewed the ad significantly more than males in terms of impressions, confirmed through a two-sample z-test
  - There is a moderate difference in the amount of impressions by age, with the age group recieiving the most being 25-35 and the least being 65+. Found using ANOVA test with a p-value < 0.05 for significance and < 0.1 for moderate significance.
  - There is no difference in amount of impressions by hour or by weekday, found using an ANOVA test. However, the day with the most impressions was Tuesday and Friday. The times with the most were in the evening or during lunch (7PM, 8PM, 1PM, 2PM, 11AM), both times when people tend to have free time in their day.
  - There is no difference in the amount of clicks recieved by keyword search, however the ones that did recieve clicks suggests the target demographic should be families / those with kids or couples / those with a partner, as top keywords contained words like 'kids' or 'couples'.

**Overall** 
  - TikTok had the largest reach as well as clicks, but the lowest conversion rate (1.13%) and second lowest click through rate (3.45%). Facebook had the seconed highest reach and clicks, with the best conversion rate by a land slide (30.96%), and the best click through rate (4.6%). Google performed the worst, with the lowest amount of impressions and clicks, as well as lowest click through rate (1.14%) and second lowest conversion rate (3.1%).
  - TikTok had the lowest cost per click (0.22$) with the highest total cost (120$), facebook had the second highest cost per click (0.42$) and the second highest total cost (100.4$), lastly Google having the highest CPC (0.53$) but lowest total cost (56.19$). 
  - TikTok recieved the most views, but it had the lowest conversion rate and second lowest click through rate. Therefore, Facebook out performed TikTok and can be selected as the best performing platform for these metrics.
  - While google had the lowest total cost, it had the lowest amount of clicks, which resulted in the low cost irregardless of it having the highest cost per click. Additionally, it had the worst click through and second lowest conversion rate. TikTok had the highest total cost, but it also had the most views resutling in the high cost despite it having the lowest cost per click. Facebook had the second lowest total cost and cost per click, as well as the second highest reach. Taking only cost and reach into account, TikTok would be the superior choice. However, taking all metrics into account, Facebook is the best choice.
  - Using facebook, the target demographic should be men and older age groups, as they were most likely to convert. If the time of day is going to be manually selected, the times should be either early mornings or lunch hours as that is when people in older age groups are more likely to be on social media and view the ad. Additionally, the ad should be catered to target families or couples, as revealed in the Google keyword search results.

## Python

### Analyzing TikTok Video Statistics

**Code:** 
[(TikTok Claim Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/tiktok_claim_analysis/tiktok_video_stats.ipynb)
[(Claim Hypthosesis Testing)](https://github.com/ariannalangton/Portfolio/blob/main/tiktok_claim_analysis/tiktok_hypothesis_testing.ipynb)

**Dashboard:** [(EDA of TikTok Claim Classification)](https://public.tableau.com/app/profile/arianna.langton5684/viz/EDAofTiktokClaimClassification/Story1)

**Goal:** Use skills to clean and investigate data following EDA process. Analyze data for TikTok videos and discover trends.

**Description:** For this project I will assist the TikTok analyst team by doing some Exploratory Data Analysis (EDA) and data visualization on a dataset provided by the google data anlytics certificate. The TikTok management team asked to see a Python notebook showing data structuring and cleaning, as well as any matplotlib/seaborn visualizations plotted to help us understand the data. I will analyze claim counts to opinion counts, as well as boxplots of statistics such as “video duration,” “video like count,” “video comment count,” and “video view count” to check for outliers. In addition, I will do a breakdown of “author ban status” counts. I will then perform a hypothesis test to see if the results have any statistical significance.

**Skills:** data cleaning, data analysis, data visualization.

**Technology:** Python, Pandas, Numpy, Seaborn, Matplotlib

**Results:** I observed that TikTok videos flagged as claims receive significantly more views than those flagged as opinions, despite a similar number of videos being posted for both categories. Furthermore, the author status of the user is mainly active across both claim types. However, the proportion of active authors is greater in the opinion category. This suggests that users posting claims are more likely to have their accounts banned or under review. Additionally, all video statistics showed a right-skewed distribution, except for video duration, which exhibited a fairly uniform distribution. Overall, videos that posts claims are likely to get more views and likes than those that are opinions, but the account status is more likely to be banned or under review.

### Analyzing Marketing Campaigns on Different Platforms

**Code:** [(General Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/marketing_budget_analysis/linearRegression_TVbudget_sales.ipynb)
[(Radio vs Sales Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/marketing_budget_analysis/linearRegression_radioBudget_sales.ipynb)

**Goal:** Anlyze data for trends between sales and allocated budget using linear regression. Select the platform with the best relationship between budget and sales generated to recommend for further invesetment.

**Description:** For this activity, I will explore the relationship between marketing promotional budgets and sales using linear regression. The dataset provided includes information about the budget allocated for marketing campaigns across TV, radio, and social media, as well as how much revenue in sales was generated from these campaigns. I will select the platforms that have the most promising relationship between sales and budget and investigate further. After the general analysis, I will also explore the relationship between the radio promotion budget and the sales revenue. Based on this information, decisions about where to focus future marketing efforts will be made, so it is critical to have a clear understanding of the relationship between the different types of marketing and the revenue they generate. 

**Skills:** data cleaning, data analysis, data visualization, regression analysis.

**Technology:** Python, Pandas, Numpy, Seaborn, Matplotlib, statsmodels

**Results:** After analyzing the data  using linear regression and performing hypothesis tests for significance, I was able to reject the null hypothesis and state that there is a relationship between radio promotion budget and sales for companies in this data. However, of the three available promotion types (TV, radio, and social media), TV has the strongest positive linear relationship with sales. According to the model, an increase of one million dollars for the TV promotional budget will result in an estimated 3.5614 million dollars more in sales. Using statistical methods of evaluation I can say this is a very confident estimate, as the p-value for this coefficient estimate is small. Thus, the business should prioritize increasing the TV promotional budget over the radio and social media promotional budgets to increase sales.


### Analyzing Industries and Countires for Investments

**Code:** 
[(Investment Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/unicorn_investment_analysis/inevstor_analysis.ipynb)
[(Unicorn Company Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/unicorn_investment_analysis/unicorn_companies.ipynb)
[(Unicorn Company Trends Analysis)](https://github.com/ariannalangton/Portfolio/blob/main/unicorn_investment_analysis/time_to_unicorn_analysis.ipynb)

**Goal:** Use skills to clean and investigate data following EDA process. Analyze data for companies in different industries and countries as well as data trends, and find 'Unicorn Companies.'

**Description:** I provided insights to an imaginary investing firm. To help them decide which companies to invest in next, the firm wants insights into unicorn companies–companies that are valued at over one billion dollars. The data I used for this task provides information on over 1,000 unicorn companies, including their industry, country, year founded, and select investors. The investor wants companies in the hardware industry based in Beijing, San Francisco, and London. They also want to investigate companies in the artificial intelligence industry based in London. They requested a list of the top 20 countries sorted by company valuations in each country as well as a global valuation map of all countries except United States, China, India, and United Kingdom. In addition, I used this information to gain insights into how and when companies reach this prestigious milestone and to make recommendations for next steps to the investing firm. The investor was particularly interested in understanding the patterns and timing of when companies achieve unicorn status, so I analyzed the data across various timeframes, including years, months, weeks, and quarters.

**Skills:** data cleaning, data analysis, data visualization.

**Technology:** Python, Pandas, Numpy, Seaborn, Matplotlib

**Results:** 
The analysis identified eight companies in the Hardware and AI industries that meet the criteria: Bitmain, Global Switch, Chipone, Density, BenevolentAI, Geek+, TERMINUS Technology, and Tractable. The top five countries by valuation are Germany, Sweden, Australia, France, and Canada. A plot of the top 20 companies is available in the notebook. Europe shows a high concentration of unicorns in a specific region. The dataset includes 1,074 unicorn companies, some of which took longer to reach $1 billion due to factors like funding needs or business model development. The highest concentration of unicorn startups occurred in 2015. Companies founded more recently tend to reach unicorn status faster. In 2021, Week 37 (third week of September) saw the highest number of companies achieving a $1 billion valuation, followed by a decline in unicorns afterward.

### Air Quality Probability Density
**Code:** 
[(Air Quality Inital Sampling)](https://github.com/ariannalangton/Portfolio/blob/main/air_quality_index_analysis/AQI_sampling.ipynb)
[(Air Quality Probability Density)](https://github.com/ariannalangton/Portfolio/blob/main/air_quality_index_analysis/airQuality_probabilityDistrib.ipynb)
[(Air Quality Confidence Intervals)](https://github.com/ariannalangton/Portfolio/blob/main/air_quality_index_analysis/AQI_confidence_intervals.ipynb)
[(Air Quality Hypothesis Testing)](https://github.com/ariannalangton/Portfolio/blob/main/air_quality_index_analysis/hypothesis_testing_practice.ipynb)

**Goal:** Use skills to find what probability distribution fits the data, then use Z-score to find outliers, and finally use hypothesis tests and confidence intervals to check for statistical significane. 

**Description:** I will be using data from the United States Environmental Protection Agency (EPA). The data includes information about more than 200 sites, identified by state, county, city, and local site names. One of the main goals is to determine which regions need support to make air quality improvements. Given that carbon monoxide is a major air pollutant, I will investigate data from the Air Quality Index (AQI) with respect to carbon monoxide. An AQI over 10 would qualify the area for support. I will use the central limit theorem to prove that data can be fit by a normal distribution. I will then perform hypothesis tests and calculate confidence intervals to see if the results of the findings are statistically significant and should be used to decide which states need support.

**Skills:** data cleaning, data analysis, data visualization, probability.

**Technology:** Python, Pandas, Numpy, Seaborn, Matplotlib, SciPy

**Results:** Overall, I discovered that the distribution of the aqi_log data is approximately normal. In addition, using statistical methods such a z-scores, it was determined that the site at West Phoenix has worse air quality than the other sites, and is an outlier who should be considered for support. Upon further analysis, I also identified at the 5% significance level that the Los Angeles mean AQI was statistically different from the rest of California, the confidence interval at the 95% level of confidence from this sample data yielded [10.36 , 13.88], which provides the interpretation "given the observed sample AQI measurements, there is a 95% confidence that the population mean AQI for California was between 10.36 and 13.88.” This range is notably greater than 10, and thus should be considered to receive support. In addition, it was appeared that Michigan had an AQI over 10, but upon further teseting I was unable to conclude at the 5% significance level that Michigan's mean AQI was greater than 10, and am unable to recommend it for support.

### Literacy Data Probability Density
**Code:** [(Literacy Data Probability Density)](https://github.com/ariannalangton/Portfolio/blob/main/normal_distrib_literacyData.ipynb)   

**Goal:** Use skills to find what probability distribution fits the data, and then use Z-score to find outliers. One of the main goals is to determine which district has the lowest literacy scores.

**Description:** I will be using data from different districts in the U.S. The data includes information from multiple states, and inlcudes the districts literacy score, OVERALL_LI. 

**Skills:** data cleaning, data analysis, data visualization, probability.

**Technology:** Python, Pandas, Numpy, Seaborn, Matplotlib, SciPy

**Results:** Overall, I discovered that the distribution of the aqi_log data is approximately normal. In addition, using statistical methods, it was determined that districts 434 and 494 have Z-scores less than -3, and so are outliers. As a result, there should be more focus on those districts to improve the literacy score.

### Analyzing Meteroite Landings Recorded by NASA
**Code:** [(NASA_Meteorite_data_analysis.ipynb)](https://github.com/ariannalangton/Portfolio/blob/main/NASA_Meteorite_data_analysis.ipynb)

**Goal:** Use skills to clean and investigate data following EDA process. Find and analyze most common mass, year, geographical location, name type, and meteorite class.

**Description:** The project focused on analyzing a dataset of meteorite landings from the 1400s to 2014. The dataset included name, id, name type, class, mass, fall type, year, and location. The project involved loading the data, cleaning and preprocessing it, performing exploratory data analysis (EDA), analyzing the most common type, year, and landing location of the meteorites.

**Skills:** data cleaning, data analysis, data visualization.

**Technology:** Python, Pandas, Numpy, Seaborn, Matplotlib, SciPy, Plotly Express

**Results:** Using Python functions the analysis revealed that the year with the most meteorites was 1998. However, the year with the most missing data was 2004 and was followed closely by 2003, which could have skewed the data. For location, the most common spot was (0,0), which is most likely an error. The second most common was in Antarctica. The average mass of all the meteorites was 14020 grams. The average mass was also calcualted for year as well as meteroite class. Ofcourse there are many other characteristics that could have been investigated, but this was enough for my goal.

### Chaotic Systems of Differenital Equations
**Code:** [(Chaotic differential Systems of Equations)](https://github.com/ariannalangton/Portfolio/blob/main/chaotic_systems/Chaotic_Systems.ipynb)

**Goal:** Simulate and solve three different chaotic systems of ordinary differential equations; Lorenz, Chua, Rössler. Discover what inital conditions, or coefficients, cause the system to become chaotic attractors. An attractor describes a state to which a dynamical system evolves after a long enough time.

**Description:** Utilized Python to simulate and solve three different chaotic systems of ordinary differential equations; Lorenz, Chua, Rössler. Each system is comprised of their own unique equations and coefficents.
**Skills:** data analysis, data visualization, mathematics.

**Technology:** Python, Pandas, Numpy, Matplotlib, SciPy, mpl_toolkits.mplot3d

**Results:** [(Results Report)](https://github.com/ariannalangton/Portfolio/blob/main/chaotic_systems/chaotic%20attractors%20results.pdf)

## Education

Illinois State University |
Bachelor of Science, Physics |
2019 - 2023

## Certifications

Google Data Analytics Professional Certificate (Aug 2024) (Coursera - Google) <br>
Google Advanced Data Analytics Professional Certificate (Jan 2025) (Coursera - Google) <br>
Google Business Intelligence Certificate (Jan 2025) (Coursera - Google)

## Contacts
- LinkedIn: [@ariannalangton](https://www.linkedin.com/in/arianna-langton-844b03252)
- Email: anlangton00@gmail.com

